{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/trainer/blob/main/captioner.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!pip install -q tiktoken transformers_stream_generator gradio optimum auto-gptq huggingface_hub\n",
        "!pip install -q modelscope -f https://pypi.org/project/modelscope\n",
        "# !wget https://raw.githubusercontent.com/camenduru/Qwen-VL-Chat-colab/main/app.py -O /content/app.py\n",
        "# !python app.py --share\n",
        "\n",
        "import os\n",
        "from argparse import ArgumentParser\n",
        "from pathlib import Path\n",
        "import copy\n",
        "import os\n",
        "import re\n",
        "import secrets\n",
        "import tempfile\n",
        "from modelscope import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "model_dir = snapshot_download('4bit/Qwen-VL-Chat-Int4')\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, resume_download=True,)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", trust_remote_code=True, resume_download=True,).eval()\n",
        "model.generation_config = GenerationConfig.from_pretrained(model_dir, trust_remote_code=True, resume_download=True,)\n",
        "\n",
        "def _parse_text(text):\n",
        "    lines = text.split(\"\\n\")\n",
        "    lines = [line for line in lines if line != \"\"]\n",
        "    count = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"```\" in line:\n",
        "            count += 1\n",
        "            items = line.split(\"`\")\n",
        "            if count % 2 == 1:\n",
        "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
        "            else:\n",
        "                lines[i] = f\"<br></code></pre>\"\n",
        "        else:\n",
        "            if i > 0:\n",
        "                if count % 2 == 1:\n",
        "                    line = line.replace(\"`\", r\"\\`\")\n",
        "                    line = line.replace(\"<\", \"&lt;\")\n",
        "                    line = line.replace(\">\", \"&gt;\")\n",
        "                    line = line.replace(\" \", \"&nbsp;\")\n",
        "                    line = line.replace(\"*\", \"&ast;\")\n",
        "                    line = line.replace(\"_\", \"&lowbar;\")\n",
        "                    line = line.replace(\"-\", \"&#45;\")\n",
        "                    line = line.replace(\".\", \"&#46;\")\n",
        "                    line = line.replace(\"!\", \"&#33;\")\n",
        "                    line = line.replace(\"(\", \"&#40;\")\n",
        "                    line = line.replace(\")\", \"&#41;\")\n",
        "                    line = line.replace(\"$\", \"&#36;\")\n",
        "                lines[i] = \"<br>\" + line\n",
        "    text = \"\".join(lines)\n",
        "    return text\n",
        "\n",
        "uploaded_file_dir = \"/content/image\"\n",
        "\n",
        "def predict(_chatbot, task_history):\n",
        "    chat_query = _chatbot[-1][0]\n",
        "    query = task_history[-1][0]\n",
        "    # print(\"User: \" + _parse_text(query))\n",
        "    history_cp = copy.deepcopy(task_history)\n",
        "    full_response = \"\"\n",
        "\n",
        "    history_filter = []\n",
        "    pic_idx = 1\n",
        "    pre = \"\"\n",
        "    for i, (q, a) in enumerate(history_cp):\n",
        "        if isinstance(q, (tuple, list)):\n",
        "            q = f'Picture {pic_idx}: <img>{q[0]}</img>'\n",
        "            pre += q + '\\n'\n",
        "            pic_idx += 1\n",
        "        else:\n",
        "            pre += q\n",
        "            history_filter.append((pre, a))\n",
        "            pre = \"\"\n",
        "    history, message = history_filter[:-1], history_filter[-1][0]\n",
        "    response, history = model.chat(tokenizer, message, history=history)\n",
        "    image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
        "    if image is not None:\n",
        "        temp_dir = secrets.token_hex(20)\n",
        "        temp_dir = Path(uploaded_file_dir) / temp_dir\n",
        "        temp_dir.mkdir(exist_ok=True, parents=True)\n",
        "        name = f\"tmp{secrets.token_hex(5)}.jpg\"\n",
        "        filename = temp_dir / name\n",
        "        image.save(str(filename))\n",
        "        _chatbot[-1] = (_parse_text(chat_query), (str(filename),))\n",
        "        chat_response = response.replace(\"<ref>\", \"\")\n",
        "        chat_response = chat_response.replace(r\"</ref>\", \"\")\n",
        "        chat_response = re.sub(BOX_TAG_PATTERN, \"\", chat_response)\n",
        "        if chat_response != \"\":\n",
        "            _chatbot.append((None, chat_response))\n",
        "    else:\n",
        "        _chatbot[-1] = (_parse_text(chat_query), response)\n",
        "    full_response = _parse_text(response)\n",
        "\n",
        "    task_history[-1] = (query, full_response)\n",
        "    # print(\"Qwen-VL-Chat: \" + _parse_text(full_response))\n",
        "    task_history = task_history[-10:]\n",
        "    return _chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login --token\n",
        "!mkdir /content/images\n",
        "!wget https://huggingface.co/camenduru/polaroid/resolve/main/polaroid.zip\n",
        "!unzip style_name_fix.zip -d /content/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import Dataset, Image\n",
        "\n",
        "file_names = os.listdir('/content/images')\n",
        "sorted_file_names = sorted(file_names)\n",
        "image = []\n",
        "text = []\n",
        "for file_name in sorted_file_names[:10]:\n",
        "    try:\n",
        "      _chatbot = [[(f'/content/images/{file_name}',), None], ['Describe the image and color details.', None]]\n",
        "      result = predict(_chatbot, _chatbot)\n",
        "      print(result[0][0][0],'||',result[1][1])\n",
        "      image.append(result[0][0][0])\n",
        "      text.append(result[1][1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "ds = Dataset.from_dict({\"image\": image, \"text\": text})\n",
        "ds = ds.cast_column(\"image\", Image())\n",
        "print(len(image), len(text))\n",
        "ds.push_to_hub(f\"camenduru/test-polaroid\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
