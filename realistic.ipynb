{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/trainer/blob/main/realistic.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!apt -y update -qq\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "%env TF_CPP_MIN_LOG_LEVEL=1\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!pip install -q torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "!pip install -q xformers==0.0.20 triton==2.0.0 diffusers==0.19.0 datasets==2.14.0 gradio==3.38.0 wandb==0.15.7 transformers==4.26.0 accelerate==0.16.0 bitsandbytes==0.41.0 -U\n",
        "\n",
        "!git clone https://github.com/camenduru/trainer\n",
        "\n",
        "diffusers_version = \"v0.19.0\"\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://raw.githubusercontent.com/huggingface/diffusers/{diffusers_version}/scripts/convert_diffusers_to_original_stable_diffusion.py -d /content/trainer/diffusers/dreambooth -o convert_diffusers_to_original_stable_diffusion.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://raw.githubusercontent.com/huggingface/diffusers/{diffusers_version}/examples/dreambooth/train_dreambooth.py -d /content/trainer/diffusers/dreambooth -o train_dreambooth.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://raw.githubusercontent.com/huggingface/diffusers/{diffusers_version}/examples/dreambooth/train_dreambooth_lora.py -d /content/trainer/diffusers/lora -o train_dreambooth_lora.py\n",
        "\n",
        "BaseModelUrl = \"https://huggingface.co/uf/cyberrealistic_v3.2\"\n",
        "BaseModelDir = \"/content/model\"\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/model_index.json -d {BaseModelDir} -o model_index.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/resolve/main/vae/diffusion_pytorch_model.bin -d {BaseModelDir}/vae -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/vae/config.json -d {BaseModelDir}/vae -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/resolve/main/unet/diffusion_pytorch_model.bin -d {BaseModelDir}/unet -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/unet/config.json -d {BaseModelDir}/unet -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/tokenizer/vocab.json -d {BaseModelDir}/tokenizer -o vocab.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/tokenizer/tokenizer_config.json -d {BaseModelDir}/tokenizer -o tokenizer_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/tokenizer/special_tokens_map.json -d {BaseModelDir}/tokenizer -o special_tokens_map.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/tokenizer/merges.txt -d {BaseModelDir}/tokenizer -o merges.txt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/resolve/main/text_encoder/pytorch_model.bin -d {BaseModelDir}/text_encoder -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/text_encoder/config.json -d {BaseModelDir}/text_encoder -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/scheduler/scheduler_config.json -d {BaseModelDir}/scheduler -o scheduler_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/resolve/main/safety_checker/pytorch_model.bin -d {BaseModelDir}/safety_checker -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/safety_checker/config.json -d {BaseModelDir}/safety_checker -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {BaseModelUrl}/raw/main/feature_extractor/preprocessor_config.json -d {BaseModelDir}/feature_extractor -o preprocessor_config.json\n",
        "\n",
        "%cd /content/trainer\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "import os, shutil\n",
        "import gradio as gr\n",
        "from gradio import strings\n",
        "from shared import Shared\n",
        "\n",
        "trainer = gr.Blocks(title=\"Trainer\")\n",
        "\n",
        "def upload_file(files):\n",
        "    !rm -rf /content/images\n",
        "    file_paths = [file.name for file in files]\n",
        "    if not os.path.exists('/content/images'):\n",
        "        os.mkdir('/content/images')\n",
        "    for file_path in file_paths:\n",
        "        shutil.copy(file_path, '/content/images/')\n",
        "    return file_paths\n",
        "\n",
        "def launch():\n",
        "    strings.en[\"SHARE_LINK_MESSAGE\"] = f\"ðŸ˜Š\"\n",
        "    with trainer:\n",
        "        with gr.Group():\n",
        "          with gr.Row():\n",
        "              with gr.Box():\n",
        "                gallery = gr.Gallery()\n",
        "                files = gr.Files(label=\"Upload Images\", file_types=[\"image\"], file_count=\"multiple\")\n",
        "                files.upload(fn=upload_file, inputs=files, outputs=gallery)\n",
        "              with gr.Box():\n",
        "                  train_lora_command = \"\"\"python -u /content/trainer/diffusers/lora/train_dreambooth_lora.py \\\\\n",
        "                  --pretrained_model_name_or_path=\"/content/model\"  \\\\\n",
        "                  --instance_data_dir=\"/content/images\" \\\\\n",
        "                  --output_dir=\"/content/trainer/diffusers/lora/output_dir\" \\\\\n",
        "                  --learning_rate=5e-6 \\\\\n",
        "                  --max_train_steps=1250 \\\\\n",
        "                  --instance_prompt=\"âš  INSTANCE PROMPT\" \\\\\n",
        "                  --resolution=512 \\\\\n",
        "                  --center_crop \\\\\n",
        "                  --train_batch_size=1 \\\\\n",
        "                  --gradient_accumulation_steps=1 \\\\\n",
        "                  --max_grad_norm=1.0 \\\\\n",
        "                  --mixed_precision=\"fp16\" \\\\\n",
        "                  --gradient_checkpointing \\\\\n",
        "                  --enable_xformers_memory_efficient_attention \\\\\n",
        "                  --use_8bit_adam \\\\\n",
        "                  --train_text_encoder\"\"\"\n",
        "                  lora_command = gr.Textbox(show_label=False, lines=16, value=train_lora_command)\n",
        "                  train_lora_out_text = gr.Textbox(show_label=False)\n",
        "                  btn_train_lora_run_live = gr.Button(\"Train Lora\")\n",
        "                  btn_train_lora_run_live.click(Shared.run_live, inputs=lora_command, outputs=train_lora_out_text, show_progress=False)\n",
        "        with gr.Group():\n",
        "          with gr.Row():\n",
        "              with gr.Box():\n",
        "                  image = gr.Image(show_label=False)\n",
        "              with gr.Box():\n",
        "                  model_dir = gr.Textbox(label=\"Enter your output dir\", show_label=False, max_lines=1, value=\"/content/model\")\n",
        "                  output_dir = gr.Textbox(label=\"Enter your output dir\", show_label=False, max_lines=1, value=\"/content/trainer/diffusers/lora/output_dir\")\n",
        "                  prompt = gr.Textbox(label=\"prompt\", show_label=False, max_lines=1, placeholder=\"Enter your prompt\")\n",
        "                  negative_prompt = gr.Textbox(label=\"negative prompt\", show_label=False, max_lines=1, placeholder=\"Enter your negative prompt\")\n",
        "                  steps = gr.Slider(label=\"Steps\", minimum=5, maximum=50, value=25, step=1)\n",
        "                  scale = gr.Slider(label=\"Guidance Scale\", minimum=0, maximum=50, value=7.5, step=0.1)\n",
        "                  checkbox = gr.Checkbox(label=\"Load Model\", value=True)\n",
        "                  btn_test_lora = gr.Button(\"Generate image\")\n",
        "                  btn_test_lora.click(Shared.test_lora, inputs=[model_dir, checkbox, output_dir, prompt, negative_prompt, steps, scale], outputs=image)\n",
        "    trainer.queue().launch(debug=True, share=True, inline=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
